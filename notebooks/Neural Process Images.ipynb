{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6 : Neural Process Images\n",
    "\n",
    "Last Update : 25 July 2019\n",
    "\n",
    "**Aim**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8\n",
    "# Nota Bene : notebooks don't deallocate GPU memory\n",
    "IS_FORCE_CPU = False # can also be set in the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/master\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
       ".prompt display:none;}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# CENTER PLOTS\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"\"\" <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
    ".prompt display:none;}  </style>\"\"\"))\n",
    "\n",
    "import os\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset \n",
    "\n",
    "SVHN \n",
    "MNIST\n",
    "CELEBA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE    \u001b[0m\u001b[01;34mbin\u001b[0m/   \u001b[01;34mimgs\u001b[0m/  \u001b[01;34mneuralproc\u001b[0m/  requirements.txt  \u001b[01;34mutils\u001b[0m/\r\n",
      "README.md  \u001b[01;34mdata\u001b[0m/  \u001b[01;34mlogs\u001b[0m/  \u001b[01;34mnotebooks\u001b[0m/   \u001b[01;34mresults\u001b[0m/          \u001b[01;32mvenv.sh\u001b[0m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Attention.ipynb\r\n",
      "Extended Attn vs Conv CNP Large.ipynb\r\n",
      "Extended Attn vs Conv CNP.ipynb\r\n",
      "Human Activity Recognition - GNP JOINT Consistency.ipynb\r\n",
      "Paper Replication - Attentive Neural Process.ipynb\r\n",
      "Tutorial 1 - Conditional Neural Process.ipynb\r\n",
      "Tutorial 2 - Neural Process.ipynb\r\n",
      "Tutorial 3 - Attentive (Conditional) Neural Process.ipynb\r\n",
      "Tutorial 4 - Attentive Neural Process Variants.ipynb\r\n",
      "Tutorial 5 - GNP [WIP].ipynb\r\n",
      "Tutorial 5 - U-GNP [WIP].ipynb\r\n",
      "Tutorial 5 - U-GNP-mini-summary [WIP].ipynb\r\n",
      "Tutorial 5 - U-GNP-summary [WIP]-Copy1.ipynb\r\n",
      "Tutorial 5 - U-GNP-summary [WIP].ipynb\r\n",
      "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/\r\n",
      "ntbks_helpers.py\r\n"
     ]
    }
   ],
   "source": [
    "ls notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ntbks_add_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-299add52617f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mntbks_add_data\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0madddata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssldata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_train_dev_test_ssl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ntbks_add_data'"
     ]
    }
   ],
   "source": [
    "import ntbks_add_data as adddata \n",
    "from utils.data.ssldata import get_dataset, get_train_dev_test_ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=adddata.get_dataset(\"celeba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba = adddata.get_dataset(\"celeba\")()\n",
    "svhn = get_dataset(\"svhn\")()\n",
    "mnist_train, _, mnist_test = get_train_dev_test_ssl(\"mnist\", dev_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVHN\n",
    "im_idx = 1\n",
    "plt.imshow(svhn[im_idx][0].permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELEBA\n",
    "plt.imshow(celeba[im_idx][0].permute(1, 2, 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "im_idx = 1\n",
    "# SAMPLED IMAGE\n",
    "plt.imshow(mnist_test[im_idx][0].squeeze(0), cmap='gray') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skssl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f1848da771e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuralproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasplit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridCntxtTrgtGetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomMasker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_masker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_timeseries_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseMultiTimeSeriesDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m get_cntxt_trgt_test = GridCntxtTrgtGetter(context_masker=RandomMasker(min_nnz=0.1, max_nnz=0.5),\n\u001b[1;32m      5\u001b[0m                                      \u001b[0mtarget_masker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_masker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skssl'"
     ]
    }
   ],
   "source": [
    "from skssl.transformers.neuralproc.datasplit import GridCntxtTrgtGetter, RandomMasker, no_masker\n",
    "from utils.data.tsdata import get_timeseries_dataset, SparseMultiTimeSeriesDataset\n",
    "\n",
    "get_cntxt_trgt_test = GridCntxtTrgtGetter(context_masker=RandomMasker(min_nnz=0.1, max_nnz=0.5),\n",
    "                                     target_masker=no_masker,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt_feat = GridCntxtTrgtGetter(context_masker=get_all_indcs,\n",
    "                                     target_masker=no_masker,\n",
    "                                     is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "get_cntxt_trgt = GridCntxtTrgtGetter(context_masker=RandomMasker(min_nnz=0.1, max_nnz=0.5),\n",
    "                                 target_masker=RandomMasker(min_nnz=0.5, max_nnz=0.99),\n",
    "                                 is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "def cntxt_trgt_collate(get_cntxt_trgt, is_repeat_batch=False):\n",
    "    def mycollate(batch):\n",
    "        min_length = min([v.size(0) for b in batch for k,v in b[0].items() if \"X\" in k])\n",
    "        # chose first min_legth of each (assumes that randomized)\n",
    "        \n",
    "        batch = [({k:v[:min_length, ...] for k,v in b[0].items()}, b[1]) for b in batch]        \n",
    "        collated = torch.utils.data.dataloader.default_collate(batch)\n",
    "        \n",
    "        X = collated[0][\"X\"]\n",
    "        y = collated[0][\"y\"]\n",
    "        \n",
    "        if is_repeat_batch:\n",
    "            \n",
    "            X = torch.cat([X,X], dim=0)\n",
    "            y = torch.cat([y,y], dim=0)\n",
    "            collated[1] = torch.cat([collated[1], collated[1]], dim=0) # targets\n",
    "        \n",
    "        collated[0][\"X\"], collated[0][\"y\"], collated[0][\"X_trgt\"], collated[0][\"y_trgt\"] = get_cntxt_trgt(X, y)\n",
    "        \n",
    "        return collated\n",
    "    return mycollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6aac76a3f3d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "data = mnist\n",
    "datasets = dict(mnist=mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM = 2  # 2D spatial input \n",
    "Y_DIM = data.shape[0]\n",
    "N_TARGETS = data.n_classes\n",
    "\n",
    "sampling_percentages = [1]\n",
    "label_percentages = [N_TARGETS, N_TARGETS*2, 0.01, 0.05, 0.1, 0.3, 0.5, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/skssl/predefined/mlp.py:65: UserWarning: hidden_size=32 smaller than output=128 and input=128. Setting it to 128.\n",
      "  warnings.warn(txt.format(hidden_size, output_size, input_size, self.hidden_size))\n"
     ]
    }
   ],
   "source": [
    "from skssl.transformers import GlobalNeuralProcess, AttentiveNeuralProcess\n",
    "from skssl.predefined import UnetCNN, CNN, SelfAttention, MLP\n",
    "\n",
    "\n",
    "anp_kwargs = dict(r_dim=128, \n",
    "                  get_cntxt_trgt=get_cntxt_trgt,\n",
    "                  attention=\"transformer\",\n",
    "                  encoded_path=\"deterministic\")\n",
    "\n",
    "\n",
    "# initialize one model for each dataset\n",
    "data_models = {name: (AttentiveNeuralProcess(X_DIM, Y_DIM, **anp_kwargs), data) \n",
    "                   for name, data in datasets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Param: 181346\n"
     ]
    }
   ],
   "source": [
    "for k, (neural_proc, dataset) in data_models.items():\n",
    "    print(\"N Param:\", count_parameters(neural_proc))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntbks_helpers import train_all_models_\n",
    "\n",
    "train_all_models_(data_models, \"results/notebooks/neural_process/u_gnp_layer14\",\n",
    "                  is_retrain=True) # if false load precomputed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
