{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5 : GNP [WIP]\n",
    "\n",
    "Last Update : 22 June 2019\n",
    "\n",
    "**Aim**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 8\n",
    "# Nota Bene : notebooks don't deallocate GPU memory\n",
    "IS_FORCE_CPU = False # can also be set in the trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/master\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(600000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 600 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
       ".prompt display:none;}  </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%autosave 600\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# CENTER PLOTS\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"\"\" <style> .output_png {display: table-cell; text-align: center; margin:auto; }\n",
    ".prompt display:none;}  </style>\"\"\"))\n",
    "\n",
    "import os\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "    \n",
    "import sys\n",
    "sys.path.append(\"notebooks\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset we will be using are simple functions sampled from different Gaussian kernel. See [Tutorial 1 - Conditional Neural Process] for more details.\n",
    "\n",
    "[Tutorial 1 - Conditional Neural Process]: Tutorial%201%20-%20Conditional%20Neural%20Process.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize import plot_posterior_samples, plot_prior_samples, plot_dataset_samples\n",
    "from ntbks_helpers import get_gp_datasets # defined in first tutorial (CNP)\n",
    "\n",
    "X_DIM = 1  # 1D spatial input\n",
    "Y_DIM = 1  # 1D regression\n",
    "N_POINTS = 128\n",
    "N_SAMPLES = 100000 # this is a lot and can work with less\n",
    "datasets = get_gp_datasets(n_samples=N_SAMPLES, n_points=N_POINTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralproc import GlobalNeuralProcess, merge_flat_input, discard_ith_arg\n",
    "from ntbks_helpers import CNP_KWARGS # defined in first tutorial (CNP)\n",
    "from neuralproc.utils.datasplit import CntxtTrgtGetter, GetRandomIndcs\n",
    "from neuralproc.predefined import CNN, MLP\n",
    "from neuralproc.utils.helpers import change_param\n",
    "\n",
    "get_cntxt_trgt = CntxtTrgtGetter(contexts_getter=GetRandomIndcs(min_n_indcs=0.05, max_n_indcs=.5),\n",
    "                                 targets_getter=GetRandomIndcs(min_n_indcs=0.05, max_n_indcs=.5),\n",
    "                                 is_add_cntxts_to_trgts=False)  # don't context points to tagrtes\n",
    "\n",
    "gnp_kwargs = dict(r_dim=64, \n",
    "                  get_cntxt_trgt=get_cntxt_trgt,\n",
    "                  #keys_to_tmp_attn=\"weighted_dist\",\n",
    "                 TmpSelfAttn=change_param(CNN,\n",
    "                              Conv=torch.nn.Conv1d,\n",
    "                              n_layers=5,\n",
    "                              is_depth_separable=True,\n",
    "                              Normalization=torch.nn.BatchNorm1d,\n",
    "                              is_chan_last=True,\n",
    "                              kernel_size=7),\n",
    "                 #tmp_to_queries_attn=\"weighted_dist\",\n",
    "                  #XEncoder=torch.nn.Linear,\n",
    "                  #XYEncoder=discard_ith_arg(MLP, i=0),\n",
    "                  #x_transf_dim=None,\n",
    "                 #is_use_x=False\n",
    "                 )\n",
    "\n",
    "# initialize one model for each dataset\n",
    "data_models = {name: (GlobalNeuralProcess(X_DIM, Y_DIM, **gnp_kwargs), data) \n",
    "                   for name, data in datasets.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N Param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of parameters (note that I did not play around with this much, this depends a lot on the representation size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.helpers import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Param: 28936\n"
     ]
    }
   ],
   "source": [
    "for k, (neural_proc, dataset) in data_models.items():\n",
    "    print(\"N Param:\", count_parameters(neural_proc))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `\"transformer\"` attention increases the number of parameters, but using a deterministic path as well a smaller representation seize decreases the number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fde1ce05518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5399e-05])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softplus(torch.tensor([-10.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training rbf ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1563), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  epoch    train_loss    cp       dur\n",
      "-------  ------------  ----  --------\n",
      "      1        \u001b[36m0.4660\u001b[0m     +  449.2805\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bade1fa6aabc4ae18842b3c9e9c39e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1563), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ntbks_helpers import train_all_models_\n",
    "\n",
    "train_all_models_(data_models, \"results/notebooks/neural_process/gnp\",\n",
    "                  is_retrain=True) # if false load precomputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model converges extremely quickly ($\\sim 15$ epochs)  but already has very good predictions after $\\sim 5$ epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "## Trained Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRAP_DISTANCE = 1.5  # add 1.5 to the right for extrapolation\n",
    "INTERPOLATION_RANGE = dataset.min_max\n",
    "EXTRAPOLATION_RANGE = (dataset.min_max[0], dataset.min_max[1]+EXTRAP_DISTANCE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,(neural_proc, dataset) in data_models.items():\n",
    "    plot_prior_samples(neural_proc, \n",
    "                       title=\"Trained Prior Samples : {}\".format(k), \n",
    "                       test_min_max=EXTRAPOLATION_RANGE, \n",
    "                       train_min_max=INTERPOLATION_RANGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,(neural_proc, dataset) in data_models.items():\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralproc.utils.helpers import rescale_range\n",
    "\n",
    "for k,(neural_proc, dataset) in data_models.items():\n",
    "    extrap_rescaled_range = tuple(rescale_range(np.array(EXTRAPOLATION_RANGE), (-2,2), (-1,1)))\n",
    "    neural_proc.extend_tmp_queries(extrap_rescaled_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CNTXT = 10\n",
    "for k,(neural_proc, dataset) in data_models.items():\n",
    "    plot_posterior_samples(dataset, neural_proc, \n",
    "                           n_cntxt=N_CNTXT, \n",
    "                           test_min_max=EXTRAPOLATION_RANGE, \n",
    "                           n_points=3*N_POINTS,\n",
    "                           n_samples=1,\n",
    "                           title=\"Posterior Samples Conditioned on {} Context Points : {}\".format(N_CNTXT, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CNTXT = 2\n",
    "for k,(neural_proc, dataset) in data_models.items():\n",
    "    plot_posterior_samples(dataset, neural_proc, \n",
    "                           n_cntxt=N_CNTXT, \n",
    "                           test_min_max=EXTRAPOLATION_RANGE, \n",
    "                           n_points=2*N_POINTS,\n",
    "                           n_samples=1,\n",
    "                           title=\"Posterior Samples Conditioned on {} Context Points : {}\".format(N_CNTXT, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CNTXT = 20\n",
    "for k,(neural_proc, dataset) in data_models.items():\n",
    "    plot_posterior_samples(dataset, neural_proc, \n",
    "                           n_cntxt=N_CNTXT, \n",
    "                           test_min_max=EXTRAPOLATION_RANGE, \n",
    "                           n_points=2*N_POINTS,\n",
    "                           n_samples=1,\n",
    "                           title=\"Posterior Samples Conditioned on {} Context Points : {}\".format(N_CNTXT, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CNTXT = 1\n",
    "for k,(neural_proc, dataset) in data_models.items():\n",
    "    plot_posterior_samples(dataset, neural_proc, \n",
    "                           n_cntxt=N_CNTXT, \n",
    "                           test_min_max=EXTRAPOLATION_RANGE, \n",
    "                           n_points=2*N_POINTS,\n",
    "                           n_samples=1,\n",
    "                           title=\"Posterior Samples Conditioned on {} Context Points : {}\".format(N_CNTXT, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the predictions are much better than in [Tutorial 2 - Neural Process]\n",
    "\n",
    "**Good**:\n",
    "- often close to GP with the correct kernel\n",
    "- the uncertainty decreases close to context points\n",
    "- no more underfitting : the sampled function all go through or close to the context points\n",
    "- does all of this with \"only\" 50k param (and I did not try to go below).\n",
    "- very good results after $\\sim 5$ epochs\n",
    "\n",
    "**Bad**:\n",
    "- there seems be some strange \"jumps\" in regions far from points. This is probably due to the softmax in cross attention, indicating that a head attends to a new point. This makes the model less smooth than GP, but could probably be solved using self attention or a larger model. \n",
    "- cannot extrapolate\n",
    "- still not as smooth as GP\n",
    "- not good at periodicity\n",
    "\n",
    "[Tutorial 2 - Neural Process]: Tutorial%202%20-%20Neural%20Process.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
